{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cifar-10 CNN\n",
    "### Import, init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "keras.backend.set_image_data_format('channels_first')\n",
    "print('Using data format:', keras.backend.image_data_format())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_row, img_col, img_cnl = 32, 32, 3\n",
    "label_names = { }\n",
    "def read_imgs(filename):\n",
    "    f = open(filename, 'rb')\n",
    "    data = pickle.load(f, encoding='bytes')\n",
    "    f.close()\n",
    "    imgs = np.array(data[b'data'])\n",
    "    imgs = imgs.reshape((imgs.shape[0], img_cnl, img_row, img_col))\n",
    "    labels = np.array(data[b'labels'])\n",
    "    return imgs, labels\n",
    "def load_labels(filename):\n",
    "    f = open(filename, 'rb')\n",
    "    data = pickle.load(f, encoding='bytes')\n",
    "    f.close()\n",
    "    return data[b'label_names']\n",
    "print('# test: ')\n",
    "%time imgs, labels = read_imgs('datas/data_batch_1')\n",
    "print('# data shape:' ,imgs.shape)\n",
    "print('# label names')\n",
    "print(load_labels('datas/batches.meta'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read all data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datas\n",
    "train_x, train_y = read_imgs('datas/data_batch_1')\n",
    "for x in (2, 3, 4, 5):\n",
    "    fn = 'datas/data_batch_%d' % x\n",
    "    imgs, labels = read_imgs(fn)\n",
    "    train_x = np.concatenate((train_x, imgs))\n",
    "    train_y = np.concatenate((train_y, labels))\n",
    "test_x, test_y = read_imgs('datas/test_batch')\n",
    "\n",
    "# Load label names\n",
    "label_names = load_labels('datas/batches.meta')\n",
    "label_names = [x.decode('ascii') for x in label_names]\n",
    "\n",
    "# Categorical\n",
    "class_cnt = len(label_names)\n",
    "train_y = keras.utils.to_categorical(train_y, class_cnt)\n",
    "test_y = keras.utils.to_categorical(test_y, class_cnt)\n",
    "\n",
    "# Standard\n",
    "train_x = train_x.astype('float32')\n",
    "test_x = test_x.astype('float32')\n",
    "train_x /= 255\n",
    "test_x /= 255\n",
    "\n",
    "print('# Train data loaded:', train_x.shape[0])\n",
    "print('# Test data loaded:', test_x.shape[0])\n",
    "print('# Label names:')\n",
    "print(label_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define network structure\n",
    "Conv -> Conv -> Pooling -> Conv -> Conv -> Pooling -> Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 300\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=train_x.shape[1:]))\n",
    "model.add(keras.layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "model.add(keras.layers.Dropout(0.25))\n",
    "\n",
    "model.add(keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "model.add(keras.layers.Dropout(0.25))\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(512, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.Dense(class_cnt, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_x, train_y,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(test_x, test_y))\n",
    "model.evaluate(test_x, test_y, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('trained_model2.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
